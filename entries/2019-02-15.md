> New AI fake text generator [may be too dangerous to release, say creators](https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction).

The title is sensationalist, as most are, but signals a unique type of hesitation. “This is good. So good. In fact, it’s too good.”[^1]

While it’s difficult to pinpoint the motivation of language like this in a press release, I wonder how the individual researcher relates to the sentiment within their own practice.

How does one justify a gravitational fascination with interesting work when what makes it fascinating to the individual is perhaps dangerous at scale?

There is a [a call to open source the language model
](https://thegradient.pub/openai-please-open-source-your-language-model/), arguing historical fears of new “deceitful” technology.

[^1]: Github also now prevents unauthenticated visitors from accessing the repository for [`deepfakes`](https://github.com/deepfakes/faceswap).